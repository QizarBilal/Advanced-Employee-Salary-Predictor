{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1e2cb5",
   "metadata": {},
   "source": [
    "# Employee Salary Dataset Generation\n",
    "\n",
    "This notebook generates a comprehensive, realistic employee salary dataset for the Employee Salary Prediction System. The dataset includes various features that influence salary determination in the Indian job market.\n",
    "\n",
    "## Objectives:\n",
    "1. **Create realistic employee data** with proper distributions and correlations\n",
    "2. **Generate salary values in INR** based on multiple factors\n",
    "3. **Include data inconsistencies** to simulate real-world scenarios\n",
    "4. **Apply business logic** for salary calculation\n",
    "5. **Save the dataset** for further analysis and modeling\n",
    "\n",
    "## Dataset Features:\n",
    "- **Personal**: Age, Gender, Education Level\n",
    "- **Professional**: Years of Experience, Job Title, Department, Seniority Level\n",
    "- **Geographic**: City, State, Region\n",
    "- **Skills**: Technical Skills, Certifications, Language Skills\n",
    "- **Company**: Company Size, Industry, Company Type\n",
    "- **Performance**: Performance Rating, Bonus Percentage\n",
    "- **Target**: Annual Salary (INR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66014ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src directory to path for imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(f\"📊 Pandas version: {pd.__version__}\")\n",
    "print(f\"🔢 NumPy version: {np.__version__}\")\n",
    "print(f\"📈 Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"🌊 Seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Parameters\n",
    "CONFIG = {\n",
    "    'dataset_size': 10000,  # Number of employees to generate\n",
    "    'missing_rate': 0.05,   # Percentage of missing values to introduce\n",
    "    'outlier_rate': 0.02,   # Percentage of outliers to introduce\n",
    "    'random_state': 42,\n",
    "    'save_path': '../data/raw/',\n",
    "    'currency': 'INR'\n",
    "}\n",
    "\n",
    "# Define categorical variables and their distributions\n",
    "GENDER_DIST = ['Male', 'Female', 'Other']\n",
    "GENDER_WEIGHTS = [0.65, 0.34, 0.01]\n",
    "\n",
    "EDUCATION_LEVELS = [\n",
    "    'High School', 'Diploma', 'Bachelor', 'Master', 'PhD'\n",
    "]\n",
    "EDUCATION_WEIGHTS = [0.05, 0.15, 0.50, 0.25, 0.05]\n",
    "\n",
    "JOB_TITLES = {\n",
    "    'Technology': [\n",
    "        'Software Engineer', 'Senior Software Engineer', 'Tech Lead', 'Engineering Manager',\n",
    "        'Data Scientist', 'ML Engineer', 'DevOps Engineer', 'Product Manager',\n",
    "        'UI/UX Designer', 'Quality Analyst', 'System Administrator', 'Database Administrator'\n",
    "    ],\n",
    "    'Finance': [\n",
    "        'Financial Analyst', 'Senior Financial Analyst', 'Finance Manager', 'CFO',\n",
    "        'Accountant', 'Senior Accountant', 'Investment Analyst', 'Risk Analyst'\n",
    "    ],\n",
    "    'Marketing': [\n",
    "        'Marketing Specialist', 'Marketing Manager', 'Digital Marketing Manager',\n",
    "        'Brand Manager', 'Content Creator', 'SEO Specialist', 'Social Media Manager'\n",
    "    ],\n",
    "    'Sales': [\n",
    "        'Sales Representative', 'Senior Sales Representative', 'Sales Manager',\n",
    "        'Business Development Manager', 'Account Manager', 'Sales Director'\n",
    "    ],\n",
    "    'HR': [\n",
    "        'HR Specialist', 'HR Manager', 'Talent Acquisition Specialist',\n",
    "        'HR Business Partner', 'Compensation Analyst', 'Training Manager'\n",
    "    ],\n",
    "    'Operations': [\n",
    "        'Operations Analyst', 'Operations Manager', 'Supply Chain Manager',\n",
    "        'Project Manager', 'Business Analyst', 'Process Improvement Specialist'\n",
    "    ]\n",
    "}\n",
    "\n",
    "INDIAN_CITIES = {\n",
    "    'Tier 1': ['Mumbai', 'Delhi', 'Bangalore', 'Hyderabad', 'Chennai', 'Pune', 'Kolkata'],\n",
    "    'Tier 2': ['Ahmedabad', 'Jaipur', 'Surat', 'Lucknow', 'Kanpur', 'Nagpur', 'Indore', 'Coimbatore'],\n",
    "    'Tier 3': ['Vadodara', 'Bhopal', 'Ludhiana', 'Agra', 'Nashik', 'Faridabad', 'Meerut', 'Rajkot']\n",
    "}\n",
    "\n",
    "CITY_MULTIPLIERS = {\n",
    "    'Tier 1': 1.3,  # Higher salaries in metro cities\n",
    "    'Tier 2': 1.1,  # Moderate increase\n",
    "    'Tier 3': 1.0   # Base salary\n",
    "}\n",
    "\n",
    "SKILLS_CATEGORIES = {\n",
    "    'Technology': [\n",
    "        'Python', 'Java', 'JavaScript', 'React', 'Node.js', 'AWS', 'Docker', \n",
    "        'Kubernetes', 'SQL', 'MongoDB', 'Machine Learning', 'Data Analysis'\n",
    "    ],\n",
    "    'Finance': [\n",
    "        'Excel', 'Financial Modeling', 'SAP', 'QuickBooks', 'Bloomberg Terminal',\n",
    "        'Risk Management', 'Compliance', 'Auditing'\n",
    "    ],\n",
    "    'Marketing': [\n",
    "        'Google Analytics', 'SEO', 'SEM', 'Social Media Marketing', 'Content Marketing',\n",
    "        'Adobe Creative Suite', 'HubSpot', 'Salesforce'\n",
    "    ],\n",
    "    'General': [\n",
    "        'Project Management', 'Leadership', 'Communication', 'Problem Solving',\n",
    "        'Team Management', 'Strategic Planning', 'Data Analysis'\n",
    "    ]\n",
    "}\n",
    "\n",
    "COMPANY_SIZES = ['Startup (<50)', 'Small (50-200)', 'Medium (200-1000)', 'Large (1000-5000)', 'Enterprise (5000+)']\n",
    "COMPANY_SIZE_WEIGHTS = [0.15, 0.25, 0.30, 0.20, 0.10]\n",
    "\n",
    "INDUSTRIES = [\n",
    "    'Technology', 'Finance', 'Healthcare', 'Manufacturing', 'Retail',\n",
    "    'Consulting', 'Education', 'Real Estate', 'Media', 'Automotive'\n",
    "]\n",
    "\n",
    "print(\"✅ Configuration and parameters defined!\")\n",
    "print(f\"📊 Dataset size: {CONFIG['dataset_size']:,} employees\")\n",
    "print(f\"🎯 Target currency: {CONFIG['currency']}\")\n",
    "print(f\"📍 Cities covered: {sum(len(cities) for cities in INDIAN_CITIES.values())} across India\")\n",
    "print(f\"💼 Job titles: {sum(len(titles) for titles in JOB_TITLES.values())} different roles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca68ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation Functions\n",
    "\n",
    "def generate_basic_info(n_samples: int) -> pd.DataFrame:\n",
    "    \"\"\"Generate basic employee information.\"\"\"\n",
    "    data = {\n",
    "        'employee_id': [f'EMP_{str(i).zfill(6)}' for i in range(1, n_samples + 1)],\n",
    "        'age': np.random.normal(32, 8, n_samples).astype(int),\n",
    "        'gender': np.random.choice(GENDER_DIST, n_samples, p=GENDER_WEIGHTS),\n",
    "        'education_level': np.random.choice(EDUCATION_LEVELS, n_samples, p=EDUCATION_WEIGHTS)\n",
    "    }\n",
    "    \n",
    "    # Ensure age is within reasonable bounds\n",
    "    data['age'] = np.clip(data['age'], 22, 65)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_professional_info(basic_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generate professional information based on age and education.\"\"\"\n",
    "    df = basic_df.copy()\n",
    "    \n",
    "    # Years of experience (correlated with age and education)\n",
    "    base_experience = df['age'] - 22  # Assuming work starts at 22\n",
    "    \n",
    "    # Adjust for education level\n",
    "    education_adjustments = {\n",
    "        'High School': -2, 'Diploma': -1, 'Bachelor': 0, 'Master': 1, 'PhD': 3\n",
    "    }\n",
    "    \n",
    "    experience_adjustments = df['education_level'].map(education_adjustments)\n",
    "    df['years_experience'] = np.maximum(0, base_experience + experience_adjustments + \n",
    "                                      np.random.normal(0, 2, len(df)))\n",
    "    df['years_experience'] = np.round(df['years_experience'], 1)\n",
    "    \n",
    "    # Department (affects salary significantly)\n",
    "    departments = list(JOB_TITLES.keys())\n",
    "    dept_weights = [0.35, 0.15, 0.12, 0.15, 0.08, 0.15]  # Technology has highest weight\n",
    "    df['department'] = np.random.choice(departments, len(df), p=dept_weights)\n",
    "    \n",
    "    # Job title based on department and experience\n",
    "    job_titles = []\n",
    "    seniority_levels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        dept = row['department']\n",
    "        exp = row['years_experience']\n",
    "        \n",
    "        # Determine seniority level\n",
    "        if exp < 2:\n",
    "            seniority = 'Junior'\n",
    "        elif exp < 5:\n",
    "            seniority = 'Mid'\n",
    "        elif exp < 10:\n",
    "            seniority = 'Senior'\n",
    "        else:\n",
    "            seniority = 'Lead'\n",
    "        \n",
    "        seniority_levels.append(seniority)\n",
    "        \n",
    "        # Select job title from department\n",
    "        available_titles = JOB_TITLES[dept]\n",
    "        if seniority == 'Junior':\n",
    "            # Prefer entry-level titles\n",
    "            title = np.random.choice(available_titles[:max(1, len(available_titles)//2)])\n",
    "        elif seniority == 'Lead':\n",
    "            # Prefer senior titles\n",
    "            title = np.random.choice(available_titles[len(available_titles)//2:])\n",
    "        else:\n",
    "            title = np.random.choice(available_titles)\n",
    "        \n",
    "        job_titles.append(title)\n",
    "    \n",
    "    df['job_title'] = job_titles\n",
    "    df['seniority_level'] = seniority_levels\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_location_info(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generate location information.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # City tier distribution (Tech jobs more in Tier 1)\n",
    "    tier_probs = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['department'] == 'Technology':\n",
    "            tier_probs.append([0.6, 0.3, 0.1])  # Higher chance in Tier 1\n",
    "        elif row['department'] in ['Finance', 'Consulting']:\n",
    "            tier_probs.append([0.5, 0.35, 0.15])\n",
    "        else:\n",
    "            tier_probs.append([0.4, 0.4, 0.2])\n",
    "    \n",
    "    city_tiers = []\n",
    "    cities = []\n",
    "    states = []\n",
    "    \n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        tier = np.random.choice(['Tier 1', 'Tier 2', 'Tier 3'], p=tier_probs[i])\n",
    "        city = np.random.choice(INDIAN_CITIES[tier])\n",
    "        \n",
    "        # Map cities to states (simplified)\n",
    "        city_state_map = {\n",
    "            'Mumbai': 'Maharashtra', 'Delhi': 'Delhi', 'Bangalore': 'Karnataka',\n",
    "            'Hyderabad': 'Telangana', 'Chennai': 'Tamil Nadu', 'Pune': 'Maharashtra',\n",
    "            'Kolkata': 'West Bengal', 'Ahmedabad': 'Gujarat', 'Jaipur': 'Rajasthan',\n",
    "            'Surat': 'Gujarat', 'Lucknow': 'Uttar Pradesh', 'Kanpur': 'Uttar Pradesh',\n",
    "            'Nagpur': 'Maharashtra', 'Indore': 'Madhya Pradesh', 'Coimbatore': 'Tamil Nadu'\n",
    "        }\n",
    "        \n",
    "        state = city_state_map.get(city, 'Other')\n",
    "        \n",
    "        city_tiers.append(tier)\n",
    "        cities.append(city)\n",
    "        states.append(state)\n",
    "    \n",
    "    df['city_tier'] = city_tiers\n",
    "    df['city'] = cities\n",
    "    df['state'] = states\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_skills_and_performance(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generate skills and performance metrics.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Technical skills score (0-100)\n",
    "    skills_scores = []\n",
    "    certifications = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        dept = row['department']\n",
    "        exp = row['years_experience']\n",
    "        education = row['education_level']\n",
    "        \n",
    "        # Base skill score influenced by experience and education\n",
    "        base_score = min(85, 40 + exp * 3 + {'High School': 0, 'Diploma': 5, \n",
    "                                           'Bachelor': 10, 'Master': 15, 'PhD': 20}[education])\n",
    "        \n",
    "        # Add randomness\n",
    "        skill_score = np.clip(base_score + np.random.normal(0, 10), 20, 100)\n",
    "        skills_scores.append(round(skill_score, 1))\n",
    "        \n",
    "        # Certifications (higher for experienced and educated)\n",
    "        cert_count = 0\n",
    "        if exp > 3 and np.random.random() < 0.6:\n",
    "            cert_count += 1\n",
    "        if education in ['Master', 'PhD'] and np.random.random() < 0.4:\n",
    "            cert_count += 1\n",
    "        if dept == 'Technology' and np.random.random() < 0.5:\n",
    "            cert_count += 1\n",
    "            \n",
    "        certifications.append(cert_count)\n",
    "    \n",
    "    df['technical_skills_score'] = skills_scores\n",
    "    df['certifications_count'] = certifications\n",
    "    \n",
    "    # Performance rating (1-5 scale)\n",
    "    # Higher performers tend to earn more\n",
    "    performance_ratings = np.random.choice([2, 3, 4, 5], len(df), p=[0.05, 0.25, 0.50, 0.20])\n",
    "    df['performance_rating'] = performance_ratings\n",
    "    \n",
    "    # Language skills (English proficiency for Indian market)\n",
    "    english_levels = ['Basic', 'Intermediate', 'Advanced', 'Native']\n",
    "    english_weights = [0.1, 0.3, 0.5, 0.1]\n",
    "    df['english_proficiency'] = np.random.choice(english_levels, len(df), p=english_weights)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_company_info(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generate company information.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Company size affects salary\n",
    "    df['company_size'] = np.random.choice(COMPANY_SIZES, len(df), p=COMPANY_SIZE_WEIGHTS)\n",
    "    \n",
    "    # Industry\n",
    "    df['industry'] = np.random.choice(INDUSTRIES, len(df))\n",
    "    \n",
    "    # Company type\n",
    "    company_types = ['Private', 'Public', 'Startup', 'MNC', 'Government']\n",
    "    type_weights = [0.4, 0.15, 0.15, 0.25, 0.05]\n",
    "    df['company_type'] = np.random.choice(company_types, len(df), p=type_weights)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"✅ Data generation functions created!\")\n",
    "print(\"🔧 Functions available:\")\n",
    "print(\"   • generate_basic_info() - Age, gender, education\")\n",
    "print(\"   • generate_professional_info() - Experience, job title, department\")\n",
    "print(\"   • generate_location_info() - City, state, tier\")\n",
    "print(\"   • generate_skills_and_performance() - Skills, certifications, performance\")\n",
    "print(\"   • generate_company_info() - Company size, industry, type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c500ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary Calculation with Business Logic\n",
    "\n",
    "def calculate_salary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate realistic salaries based on multiple factors.\n",
    "    \n",
    "    Salary calculation considers:\n",
    "    - Base salary by department and seniority\n",
    "    - Experience multiplier\n",
    "    - Education bonus\n",
    "    - Location multiplier\n",
    "    - Performance bonus\n",
    "    - Skills premium\n",
    "    - Company size factor\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Base salaries by department and seniority (in INR)\n",
    "    base_salaries = {\n",
    "        'Technology': {'Junior': 400000, 'Mid': 800000, 'Senior': 1500000, 'Lead': 2500000},\n",
    "        'Finance': {'Junior': 350000, 'Mid': 650000, 'Senior': 1200000, 'Lead': 2000000},\n",
    "        'Marketing': {'Junior': 300000, 'Mid': 550000, 'Senior': 1000000, 'Lead': 1800000},\n",
    "        'Sales': {'Junior': 320000, 'Mid': 600000, 'Senior': 1100000, 'Lead': 1900000},\n",
    "        'HR': {'Junior': 280000, 'Mid': 500000, 'Senior': 900000, 'Lead': 1600000},\n",
    "        'Operations': {'Junior': 300000, 'Mid': 550000, 'Senior': 1000000, 'Lead': 1700000}\n",
    "    }\n",
    "    \n",
    "    # Education multipliers\n",
    "    education_multipliers = {\n",
    "        'High School': 0.85, 'Diploma': 0.95, 'Bachelor': 1.0, 'Master': 1.15, 'PhD': 1.3\n",
    "    }\n",
    "    \n",
    "    # Company size multipliers\n",
    "    company_size_multipliers = {\n",
    "        'Startup (<50)': 0.9, 'Small (50-200)': 0.95, 'Medium (200-1000)': 1.0,\n",
    "        'Large (1000-5000)': 1.1, 'Enterprise (5000+)': 1.2\n",
    "    }\n",
    "    \n",
    "    # Company type multipliers\n",
    "    company_type_multipliers = {\n",
    "        'Private': 1.0, 'Public': 1.1, 'Startup': 0.9, 'MNC': 1.25, 'Government': 0.8\n",
    "    }\n",
    "    \n",
    "    salaries = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Get base salary\n",
    "        base = base_salaries[row['department']][row['seniority_level']]\n",
    "        \n",
    "        # Experience factor (additional 3% per year beyond minimum)\n",
    "        min_exp_for_level = {'Junior': 0, 'Mid': 2, 'Senior': 5, 'Lead': 10}\n",
    "        extra_exp = max(0, row['years_experience'] - min_exp_for_level[row['seniority_level']])\n",
    "        exp_multiplier = 1 + (extra_exp * 0.03)\n",
    "        \n",
    "        # Education multiplier\n",
    "        edu_multiplier = education_multipliers[row['education_level']]\n",
    "        \n",
    "        # Location multiplier\n",
    "        location_multiplier = CITY_MULTIPLIERS[row['city_tier']]\n",
    "        \n",
    "        # Performance multiplier\n",
    "        performance_multiplier = {2: 0.9, 3: 1.0, 4: 1.1, 5: 1.25}[row['performance_rating']]\n",
    "        \n",
    "        # Skills premium (0-20% based on technical skills score)\n",
    "        skills_premium = 1 + (row['technical_skills_score'] / 100) * 0.2\n",
    "        \n",
    "        # Certification bonus (5% per certification)\n",
    "        cert_bonus = 1 + (row['certifications_count'] * 0.05)\n",
    "        \n",
    "        # Company factors\n",
    "        size_multiplier = company_size_multipliers[row['company_size']]\n",
    "        type_multiplier = company_type_multipliers[row['company_type']]\n",
    "        \n",
    "        # Calculate final salary\n",
    "        calculated_salary = (base * \n",
    "                           exp_multiplier * \n",
    "                           edu_multiplier * \n",
    "                           location_multiplier * \n",
    "                           performance_multiplier * \n",
    "                           skills_premium * \n",
    "                           cert_bonus * \n",
    "                           size_multiplier * \n",
    "                           type_multiplier)\n",
    "        \n",
    "        # Add some randomness (±10%)\n",
    "        random_factor = np.random.uniform(0.9, 1.1)\n",
    "        final_salary = calculated_salary * random_factor\n",
    "        \n",
    "        # Round to nearest thousand\n",
    "        final_salary = round(final_salary / 1000) * 1000\n",
    "        \n",
    "        salaries.append(final_salary)\n",
    "    \n",
    "    df['annual_salary'] = salaries\n",
    "    \n",
    "    # Calculate bonus (typically 10-30% of salary)\n",
    "    bonus_percentages = np.random.uniform(0.1, 0.3, len(df))\n",
    "    df['annual_bonus'] = (df['annual_salary'] * bonus_percentages).round()\n",
    "    \n",
    "    # Total compensation\n",
    "    df['total_compensation'] = df['annual_salary'] + df['annual_bonus']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_data_inconsistencies(df: pd.DataFrame, missing_rate: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add realistic data inconsistencies to simulate real-world data.\n",
    "    \n",
    "    This includes:\n",
    "    - Missing values\n",
    "    - Outliers\n",
    "    - Inconsistent formatting\n",
    "    - Data entry errors\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    n_samples = len(df)\n",
    "    \n",
    "    # Columns that can have missing values (excluding ID and salary)\n",
    "    columns_for_missing = [\n",
    "        'technical_skills_score', 'certifications_count', 'english_proficiency', \n",
    "        'performance_rating', 'annual_bonus'\n",
    "    ]\n",
    "    \n",
    "    # Introduce missing values\n",
    "    for col in columns_for_missing:\n",
    "        if col in df.columns:\n",
    "            n_missing = int(n_samples * missing_rate * np.random.uniform(0.5, 1.5))\n",
    "            missing_indices = np.random.choice(df.index, n_missing, replace=False)\n",
    "            df.loc[missing_indices, col] = np.nan\n",
    "    \n",
    "    # Add some outliers in salary (very high earners)\n",
    "    n_outliers = int(n_samples * 0.01)  # 1% outliers\n",
    "    outlier_indices = np.random.choice(df.index, n_outliers, replace=False)\n",
    "    df.loc[outlier_indices, 'annual_salary'] *= np.random.uniform(2, 4, n_outliers)\n",
    "    df.loc[outlier_indices, 'total_compensation'] = (df.loc[outlier_indices, 'annual_salary'] + \n",
    "                                                   df.loc[outlier_indices, 'annual_bonus'].fillna(0))\n",
    "    \n",
    "    # Add inconsistent city name formatting (some cities with different cases)\n",
    "    city_variations = {\n",
    "        'Mumbai': ['mumbai', 'MUMBAI', 'Mumbai '],\n",
    "        'Delhi': ['delhi', 'DELHI', 'New Delhi'],\n",
    "        'Bangalore': ['bangalore', 'BANGALORE', 'Bengaluru']\n",
    "    }\n",
    "    \n",
    "    for city, variations in city_variations.items():\n",
    "        city_mask = df['city'] == city\n",
    "        if city_mask.sum() > 0:\n",
    "            # Change 10% of occurrences to variations\n",
    "            change_indices = df[city_mask].sample(frac=0.1).index\n",
    "            for idx in change_indices:\n",
    "                df.loc[idx, 'city'] = np.random.choice(variations)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"✅ Salary calculation and data inconsistency functions created!\")\n",
    "print(\"💰 Salary calculation factors:\")\n",
    "print(\"   • Base salary by department & seniority\")\n",
    "print(\"   • Experience multiplier (3% per extra year)\")\n",
    "print(\"   • Education bonus (up to 30% for PhD)\")\n",
    "print(\"   • Location premium (up to 30% for Tier 1 cities)\")\n",
    "print(\"   • Performance bonus (up to 25% for top performers)\")\n",
    "print(\"   • Skills premium (up to 20% for high technical skills)\")\n",
    "print(\"   • Company size & type factors\")\n",
    "print(\"🔧 Data inconsistencies:\")\n",
    "print(\"   • Missing values (5% rate)\")\n",
    "print(\"   • Salary outliers (1% high earners)\")\n",
    "print(\"   • Inconsistent city formatting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece29a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Complete Dataset\n",
    "\n",
    "print(\"🚀 Starting dataset generation...\")\n",
    "print(f\"📊 Generating {CONFIG['dataset_size']:,} employee records...\")\n",
    "\n",
    "# Step 1: Generate basic information\n",
    "print(\"\\n1️⃣ Generating basic employee information...\")\n",
    "df = generate_basic_info(CONFIG['dataset_size'])\n",
    "print(f\"   ✅ Created {len(df):,} employee records with basic info\")\n",
    "\n",
    "# Step 2: Add professional information\n",
    "print(\"2️⃣ Adding professional information...\")\n",
    "df = generate_professional_info(df)\n",
    "print(f\"   ✅ Added experience, job titles, and seniority levels\")\n",
    "\n",
    "# Step 3: Add location information\n",
    "print(\"3️⃣ Adding location information...\")\n",
    "df = generate_location_info(df)\n",
    "print(f\"   ✅ Added city, state, and tier information\")\n",
    "\n",
    "# Step 4: Add skills and performance metrics\n",
    "print(\"4️⃣ Adding skills and performance metrics...\")\n",
    "df = generate_skills_and_performance(df)\n",
    "print(f\"   ✅ Added technical skills, certifications, and performance ratings\")\n",
    "\n",
    "# Step 5: Add company information\n",
    "print(\"5️⃣ Adding company information...\")\n",
    "df = generate_company_info(df)\n",
    "print(f\"   ✅ Added company size, industry, and type\")\n",
    "\n",
    "# Step 6: Calculate salaries\n",
    "print(\"6️⃣ Calculating salaries based on all factors...\")\n",
    "df = calculate_salary(df)\n",
    "print(f\"   ✅ Calculated realistic salaries in {CONFIG['currency']}\")\n",
    "\n",
    "# Step 7: Add data inconsistencies\n",
    "print(\"7️⃣ Adding realistic data inconsistencies...\")\n",
    "df = add_data_inconsistencies(df, CONFIG['missing_rate'])\n",
    "print(f\"   ✅ Added missing values and inconsistencies\")\n",
    "\n",
    "print(f\"\\n🎉 Dataset generation completed!\")\n",
    "print(f\"📊 Final dataset shape: {df.shape}\")\n",
    "print(f\"💾 Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"\\n📈 Quick Statistics:\")\n",
    "print(f\"   • Average salary: ₹{df['annual_salary'].mean():,.0f}\")\n",
    "print(f\"   • Median salary: ₹{df['annual_salary'].median():,.0f}\")\n",
    "print(f\"   • Salary range: ₹{df['annual_salary'].min():,.0f} - ₹{df['annual_salary'].max():,.0f}\")\n",
    "print(f\"   • Missing values: {df.isnull().sum().sum():,} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57465f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Overview and Sample\n",
    "\n",
    "print(\"📋 Dataset Overview\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n🔍 Sample Data (First 5 rows):\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\n📊 Dataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.shape[1]}\")\n",
    "print(f\"Rows: {df.shape[0]:,}\")\n",
    "\n",
    "print(f\"\\n📈 Column Information:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\n🔢 Numerical Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(f\"\\n📝 Categorical Summary:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols[:5]:  # Show first 5 categorical columns\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts().head())\n",
    "\n",
    "print(f\"\\n❌ Missing Values Summary:\")\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)\n",
    "if len(missing_summary) > 0:\n",
    "    print(missing_summary)\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Visualizations\n",
    "\n",
    "print(\"📊 Creating Dataset Visualizations...\")\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Salary Distribution\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.hist(df['annual_salary']/100000, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Salary Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Annual Salary (Lakhs INR)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Salary by Department\n",
    "plt.subplot(3, 3, 2)\n",
    "dept_salary = df.groupby('department')['annual_salary'].median().sort_values(ascending=False)\n",
    "bars = plt.bar(range(len(dept_salary)), dept_salary/100000, color='lightcoral')\n",
    "plt.title('Median Salary by Department', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Department')\n",
    "plt.ylabel('Median Salary (Lakhs INR)')\n",
    "plt.xticks(range(len(dept_salary)), dept_salary.index, rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'₹{height:.1f}L', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 3. Experience vs Salary\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.scatter(df['years_experience'], df['annual_salary']/100000, alpha=0.6, color='green')\n",
    "plt.title('Experience vs Salary', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Years of Experience')\n",
    "plt.ylabel('Annual Salary (Lakhs INR)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['years_experience'], df['annual_salary']/100000, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(df['years_experience'], p(df['years_experience']), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "# 4. Education Level Distribution\n",
    "plt.subplot(3, 3, 4)\n",
    "education_counts = df['education_level'].value_counts()\n",
    "plt.pie(education_counts.values, labels=education_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Education Level Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 5. City Tier Distribution\n",
    "plt.subplot(3, 3, 5)\n",
    "tier_counts = df['city_tier'].value_counts()\n",
    "colors = ['gold', 'lightblue', 'lightgreen']\n",
    "bars = plt.bar(tier_counts.index, tier_counts.values, color=colors)\n",
    "plt.title('Employee Distribution by City Tier', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('City Tier')\n",
    "plt.ylabel('Number of Employees')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 50,\n",
    "             f'{int(height):,}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "# 6. Salary by Company Size\n",
    "plt.subplot(3, 3, 6)\n",
    "size_salary = df.groupby('company_size')['annual_salary'].median().sort_values()\n",
    "plt.barh(range(len(size_salary)), size_salary/100000, color='orange', alpha=0.7)\n",
    "plt.title('Median Salary by Company Size', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Median Salary (Lakhs INR)')\n",
    "plt.ylabel('Company Size')\n",
    "plt.yticks(range(len(size_salary)), size_salary.index)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. Performance Rating Distribution\n",
    "plt.subplot(3, 3, 7)\n",
    "perf_counts = df['performance_rating'].value_counts().sort_index()\n",
    "plt.bar(perf_counts.index, perf_counts.values, color='purple', alpha=0.7)\n",
    "plt.title('Performance Rating Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Performance Rating')\n",
    "plt.ylabel('Number of Employees')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Age Distribution\n",
    "plt.subplot(3, 3, 8)\n",
    "plt.hist(df['age'], bins=30, alpha=0.7, color='pink', edgecolor='black')\n",
    "plt.title('Age Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Technical Skills Score Distribution\n",
    "plt.subplot(3, 3, 9)\n",
    "plt.hist(df['technical_skills_score'].dropna(), bins=30, alpha=0.7, color='cyan', edgecolor='black')\n",
    "plt.title('Technical Skills Score Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Technical Skills Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Dataset visualizations created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Visualizations with Plotly\n",
    "\n",
    "print(\"🎨 Creating Interactive Visualizations...\")\n",
    "\n",
    "# 1. Interactive Salary Distribution by Department\n",
    "fig1 = px.box(df, x='department', y='annual_salary', \n",
    "              title='Salary Distribution by Department',\n",
    "              labels={'annual_salary': 'Annual Salary (INR)', 'department': 'Department'},\n",
    "              color='department')\n",
    "fig1.update_layout(height=500, xaxis_tickangle=-45)\n",
    "fig1.show()\n",
    "\n",
    "# 2. 3D Scatter Plot: Experience vs Skills vs Salary\n",
    "fig2 = px.scatter_3d(df.dropna(), x='years_experience', y='technical_skills_score', \n",
    "                     z='annual_salary', color='department',\n",
    "                     title='3D Relationship: Experience vs Skills vs Salary',\n",
    "                     labels={\n",
    "                         'years_experience': 'Years of Experience',\n",
    "                         'technical_skills_score': 'Technical Skills Score',\n",
    "                         'annual_salary': 'Annual Salary (INR)'\n",
    "                     })\n",
    "fig2.update_layout(height=600)\n",
    "fig2.show()\n",
    "\n",
    "# 3. Geographic Distribution with Salary Information\n",
    "city_summary = df.groupby(['city', 'city_tier']).agg({\n",
    "    'annual_salary': ['mean', 'median', 'count']\n",
    "}).round(0)\n",
    "city_summary.columns = ['avg_salary', 'median_salary', 'employee_count']\n",
    "city_summary = city_summary.reset_index()\n",
    "\n",
    "fig3 = px.scatter(city_summary, x='employee_count', y='median_salary',\n",
    "                  size='avg_salary', color='city_tier',\n",
    "                  hover_name='city',\n",
    "                  title='City Analysis: Employee Count vs Median Salary',\n",
    "                  labels={\n",
    "                      'employee_count': 'Number of Employees',\n",
    "                      'median_salary': 'Median Salary (INR)',\n",
    "                      'city_tier': 'City Tier'\n",
    "                  })\n",
    "fig3.update_layout(height=500)\n",
    "fig3.show()\n",
    "\n",
    "# 4. Correlation Heatmap\n",
    "numerical_cols = ['age', 'years_experience', 'technical_skills_score', \n",
    "                  'performance_rating', 'certifications_count', 'annual_salary']\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "fig4 = px.imshow(correlation_matrix, \n",
    "                 text_auto=True, aspect=\"auto\",\n",
    "                 title='Correlation Matrix of Numerical Features',\n",
    "                 color_continuous_scale='RdBu_r')\n",
    "fig4.update_layout(height=500)\n",
    "fig4.show()\n",
    "\n",
    "# 5. Salary Trends by Multiple Factors\n",
    "fig5 = px.sunburst(df, path=['department', 'seniority_level', 'education_level'], \n",
    "                   values='annual_salary',\n",
    "                   title='Salary Distribution Hierarchy: Department → Seniority → Education')\n",
    "fig5.update_layout(height=600)\n",
    "fig5.show()\n",
    "\n",
    "print(\"✅ Interactive visualizations created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6198027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset and Generate Report\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(CONFIG['save_path'], exist_ok=True)\n",
    "\n",
    "# Save the main dataset\n",
    "main_file_path = os.path.join(CONFIG['save_path'], 'employee_salary_dataset.csv')\n",
    "df.to_csv(main_file_path, index=False)\n",
    "\n",
    "print(f\"💾 Dataset saved to: {main_file_path}\")\n",
    "print(f\"📊 File size: {os.path.getsize(main_file_path) / 1024**2:.2f} MB\")\n",
    "\n",
    "# Create a clean version without inconsistencies for comparison\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Fix city name inconsistencies\n",
    "city_corrections = {\n",
    "    'mumbai': 'Mumbai', 'MUMBAI': 'Mumbai', 'Mumbai ': 'Mumbai',\n",
    "    'delhi': 'Delhi', 'DELHI': 'Delhi', 'New Delhi': 'Delhi',\n",
    "    'bangalore': 'Bangalore', 'BANGALORE': 'Bangalore', 'Bengaluru': 'Bangalore'\n",
    "}\n",
    "\n",
    "for old_name, new_name in city_corrections.items():\n",
    "    df_clean['city'] = df_clean['city'].replace(old_name, new_name)\n",
    "\n",
    "# Save clean version\n",
    "clean_file_path = os.path.join(CONFIG['save_path'], 'employee_salary_dataset_clean.csv')\n",
    "df_clean.to_csv(clean_file_path, index=False)\n",
    "\n",
    "print(f\"🧹 Clean dataset saved to: {clean_file_path}\")\n",
    "\n",
    "# Generate Dataset Report\n",
    "report = {\n",
    "    'generation_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'dataset_info': {\n",
    "        'total_records': len(df),\n",
    "        'total_features': len(df.columns),\n",
    "        'file_size_mb': round(os.path.getsize(main_file_path) / 1024**2, 2),\n",
    "        'currency': CONFIG['currency']\n",
    "    },\n",
    "    'feature_summary': {\n",
    "        'numerical_features': len(df.select_dtypes(include=[np.number]).columns),\n",
    "        'categorical_features': len(df.select_dtypes(include=['object']).columns),\n",
    "        'missing_values_total': int(df.isnull().sum().sum()),\n",
    "        'missing_percentage': round(df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100, 2)\n",
    "    },\n",
    "    'salary_statistics': {\n",
    "        'mean_salary': float(df['annual_salary'].mean()),\n",
    "        'median_salary': float(df['annual_salary'].median()),\n",
    "        'min_salary': float(df['annual_salary'].min()),\n",
    "        'max_salary': float(df['annual_salary'].max()),\n",
    "        'std_salary': float(df['annual_salary'].std())\n",
    "    },\n",
    "    'demographics': {\n",
    "        'age_range': f\"{df['age'].min()}-{df['age'].max()}\",\n",
    "        'experience_range': f\"{df['years_experience'].min():.1f}-{df['years_experience'].max():.1f}\",\n",
    "        'gender_distribution': df['gender'].value_counts().to_dict(),\n",
    "        'education_distribution': df['education_level'].value_counts().to_dict()\n",
    "    },\n",
    "    'professional_breakdown': {\n",
    "        'departments': df['department'].value_counts().to_dict(),\n",
    "        'seniority_levels': df['seniority_level'].value_counts().to_dict(),\n",
    "        'top_job_titles': df['job_title'].value_counts().head(10).to_dict()\n",
    "    },\n",
    "    'geographic_distribution': {\n",
    "        'city_tiers': df['city_tier'].value_counts().to_dict(),\n",
    "        'top_cities': df['city'].value_counts().head(10).to_dict(),\n",
    "        'states': df['state'].value_counts().to_dict()\n",
    "    },\n",
    "    'data_quality': {\n",
    "        'duplicate_records': int(df.duplicated().sum()),\n",
    "        'outliers_detected': int((df['annual_salary'] > df['annual_salary'].quantile(0.99)).sum()),\n",
    "        'inconsistent_cities': len(set(df['city']) - set(sum(INDIAN_CITIES.values(), []))),\n",
    "        'validation_status': 'Generated with realistic business logic'\n",
    "    }\n",
    "}\\n\\n# Save report as JSON\\nimport json\\nreport_file_path = os.path.join(CONFIG['save_path'], 'dataset_generation_report.json')\\nwith open(report_file_path, 'w') as f:\\n    json.dump(report, f, indent=4)\\n\\nprint(f\\\"📋 Generation report saved to: {report_file_path}\\\")\\n\\n# Display summary\\nprint(\\\"\\\\n\\\" + \\\"=\\\"*60)\\nprint(\\\"📊 DATASET GENERATION SUMMARY\\\")\\nprint(\\\"=\\\"*60)\\nprint(f\\\"✅ Successfully generated {report['dataset_info']['total_records']:,} employee records\\\")\\nprint(f\\\"📁 Main dataset: {main_file_path}\\\")\\nprint(f\\\"🧹 Clean dataset: {clean_file_path}\\\")\\nprint(f\\\"📋 Report: {report_file_path}\\\")\\nprint(f\\\"\\\\n💰 Salary Statistics (INR):\\\")\\nprint(f\\\"   • Average: ₹{report['salary_statistics']['mean_salary']:,.0f}\\\")\\nprint(f\\\"   • Median: ₹{report['salary_statistics']['median_salary']:,.0f}\\\")\\nprint(f\\\"   • Range: ₹{report['salary_statistics']['min_salary']:,.0f} - ₹{report['salary_statistics']['max_salary']:,.0f}\\\")\\nprint(f\\\"\\\\n🏢 Department Distribution:\\\")\\nfor dept, count in report['professional_breakdown']['departments'].items():\\n    print(f\\\"   • {dept}: {count:,} ({count/report['dataset_info']['total_records']*100:.1f}%)\\\")\\nprint(f\\\"\\\\n🌍 Geographic Distribution:\\\")\\nfor tier, count in report['geographic_distribution']['city_tiers'].items():\\n    print(f\\\"   • {tier}: {count:,} ({count/report['dataset_info']['total_records']*100:.1f}%)\\\")\\nprint(f\\\"\\\\n⚠️  Data Quality:\\\")\\nprint(f\\\"   • Missing values: {report['feature_summary']['missing_values_total']:,} ({report['feature_summary']['missing_percentage']:.1f}%)\\\")\\nprint(f\\\"   • Outliers: {report['data_quality']['outliers_detected']:,}\\\")\\nprint(f\\\"   • Duplicates: {report['data_quality']['duplicate_records']:,}\\\")\\nprint(\\\"\\\\n🎉 Dataset generation completed successfully!\\\")\\nprint(\\\"🚀 Ready for data cleaning, EDA, and machine learning modeling!\\\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
